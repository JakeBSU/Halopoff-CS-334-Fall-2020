{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Failed Decision Tree Attempt </h1>\n",
    "Found a different tutorial on how to make a decision tree for this method. Works similar to the other method's I've found, and is easier to read and understand than the other method I ended up succeeding with. However, I could not seem to get the shape of my arrays correct to work with the decision tree. Built in datasets work from sklearn, but I've been unable to make the Kaggle datasets behave and I've run out of time on this assignment. Figured I'd include this to see if you understand where I am making a mistake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, gini, num_samples, num_samples_per_class, predicted_class):\n",
    "        self.gini = gini\n",
    "        self.num_samples = num_samples\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes_ = len(set(y))  \n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.tree_ = self._grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict(inputs) for inputs in X]\n",
    "\n",
    "    def _gini(self, y):\n",
    "        m = y.size\n",
    "        return 1.0 - sum((np.sum(y == c) / m) ** 2 for c in range(self.n_classes_))\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        # Need at least two elements to split a node.\n",
    "        m = y.size\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "\n",
    "        # Count of each class in the current node.\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes_)]\n",
    "\n",
    "        # Gini of current node.\n",
    "        best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n",
    "        best_idx, best_thr = None, None\n",
    "\n",
    "        # Loop through all features.\n",
    "        for idx in range(self.n_features_):\n",
    "            # Sort data along selected feature.\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "\n",
    "            num_left = [0] * self.n_classes_\n",
    "            num_right = num_parent.copy()\n",
    "            for i in range(1, m):  # possible split positions\n",
    "                c = classes[i - 1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "                gini_left = 1.0 - sum(\n",
    "                    (num_left[x] / i) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "                gini_right = 1.0 - sum(\n",
    "                    (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2  # midpoint\n",
    "\n",
    "        return best_idx, best_thr\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes_)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = tree.Node(\n",
    "            gini=self._gini(y),\n",
    "            num_samples=y.size,\n",
    "            num_samples_per_class=num_samples_per_class,\n",
    "            predicted_class=predicted_class,\n",
    "        )\n",
    "\n",
    "        if depth < self.max_depth:\n",
    "            idx, thr = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] < thr\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node.feature_index = idx\n",
    "                node.threshold = thr\n",
    "                node.left = self._grow_tree(X_left, y_left, depth + 1)\n",
    "                node.right = self._grow_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _predict(self, inputs):\n",
    " \n",
    "        node = self.tree_\n",
    "        while node.left:\n",
    "            if inputs[node.feature_index] < node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total instances: 233\n",
      "Training instances: 1871\n",
      "Validation instances: 116\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-742694de7e6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_unseen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-f424341551d3>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grow_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "from sklearn import tree\n",
    "\n",
    "with open('house-votes-84.csv', 'r') as inputFile:\n",
    "    lines = inputFile.readlines()\n",
    "    \n",
    "    choice = 0\n",
    "    X = np.array([])\n",
    "    Y = np.array([])\n",
    "    X_unseen = []\n",
    "    Y_unseen = []\n",
    "\n",
    "    count = 0\n",
    "    for line in lines:\n",
    "        if not '?' in line:\n",
    "\n",
    "            # print(line)\n",
    "\n",
    "            count = count + 1\n",
    "            values = line.split(',')\n",
    "            party = values[0]\n",
    "\n",
    "            if 'democrat' in party:\n",
    "                choice = 1\n",
    "            if 'republican' in party:\n",
    "                choice = 0\n",
    "\n",
    "            instanceValues = []\n",
    "            for index in enumerate(values, start=1):\n",
    "                if index[0] != 1:\n",
    "                    if 'n' in index[1]:\n",
    "                        instanceValues.append(0)\n",
    "                    if 'y' in index[1]:\n",
    "                        instanceValues.append(1)\n",
    "\n",
    "            # Take every other sample and set aside for validation of our decision tree\n",
    "            # In other words, don't include these rows in our training data\n",
    "\n",
    "            if count % 2 == 0:\n",
    "                Y_unseen.append(choice)\n",
    "                X_unseen.append(instanceValues)\n",
    "            else:\n",
    "                Y = np.append(Y,choice)\n",
    "                X = np.append(X,instanceValues)\n",
    "\n",
    "    print ('Total instances:', count)\n",
    "    print ('Training instances:', len(X))\n",
    "    print ('Validation instances:', len(X_unseen))\n",
    "\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(X, Y)\n",
    "    predictions = clf.predict(X_unseen)\n",
    "\n",
    "    # print (\"Predictions:\", predictions)\n",
    "    # print (\"Actual vals:\", Y_unseen)\n",
    "\n",
    "    wrongPredictions = 0\n",
    "    for (index, val) in enumerate(predictions):\n",
    "        if Y_unseen[index] != val:\n",
    "            wrongPredictions = wrongPredictions + 1\n",
    "    print ('Correctly predicted %s out of %s instances' % (len(Y_unseen)\n",
    "            - wrongPredictions, len(Y_unseen)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
