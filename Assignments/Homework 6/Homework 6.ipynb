{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Decision Tree</h1>\n",
    "\n",
    "To achieve this result, I referenced several online tutorials and our in class lecture. Many of the tutorials I found on this subject were complete and working examples of how to implement a CART Decision Tree from scratch, but disliked the data format or were written in an older version of Python (usually Python 2). Therefore, I had quite a bit of trouble even making something functional. I've included another (failed) attempt in addition to this successful one that I couldn't seem to make work.\n",
    "\n",
    "For some reason a few tutorials called the node class \"Tree\" with a capital T and then the completed tree \"tree\" with a lowercase. I found this confusing so I changed it in my implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "  class Node:\n",
    "    def __init__(self, parent=None):\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.label = None\n",
    "        self.classCounts = None\n",
    "        self.splitFeatureValue = None\n",
    "        self.splitFeature = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printBinaryDecisionTree(root, indentation=\"\"):\n",
    "   if root.children == []:\n",
    "      print( \"%s%s, %s %s\" % (indentation, root.splitFeatureValue, root.label, root.classCounts))\n",
    "   else:\n",
    "      printBinaryDecisionTree(root.children[0], indentation + \"\\t\")\n",
    "\n",
    "      if indentation == \"\": # processing the root\n",
    "         print( \"%s%s\" % (indentation, root.splitFeature))\n",
    "      else:\n",
    "         print( \"%s%s, %s\" % (indentation, root.splitFeatureValue, root.splitFeature))\n",
    "\n",
    "      if len(root.children) == 2:\n",
    "         printBinaryDecisionTree(root.children[1], indentation + \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataToDistribution(data):\n",
    "    allLabels = [label for (point, label) in data]\n",
    "    numEntries = len(allLabels)\n",
    "    possibleLabels = set(allLabels)\n",
    "\n",
    "    dist = []\n",
    "    for aLabel in possibleLabels:\n",
    "        dist.append(float(allLabels.count(aLabel)) / numEntries)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(dist):\n",
    "    return -sum([p * math.log(p, 2) for p in dist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(data, featureIndex):\n",
    "   # get possible values of the given feature\n",
    "    attrValues = [point[featureIndex] for (point, label) in data]\n",
    "\n",
    "    for aValue in set(attrValues):\n",
    "      # compute the piece of the split corresponding to the chosen value\n",
    "        dataSubset = [(point, label) for (point, label) in data\n",
    "                    if point[featureIndex] == aValue]\n",
    "\n",
    "        yield dataSubset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain(data, featureIndex):\n",
    "    \n",
    "    entropyGain = gini(dataToDistribution(data))\n",
    "\n",
    "    for dataSubset in splitData(data, featureIndex):\n",
    "          entropyGain -= gini(dataToDistribution(dataSubset))\n",
    "\n",
    "    return entropyGain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homogeneous(data):\n",
    "\n",
    "    return len(set([label for (point, label) in data])) <= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majorityVote(data, node):\n",
    "    labels = [label for (pt, label) in data]\n",
    "    choice = max(set(labels), key=labels.count)\n",
    "    node.label = choice\n",
    "    node.classCounts = dict([(label, labels.count(label)) for label in set(labels)])\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDecisionTree(data, root, remainingFeatures):\n",
    "\n",
    "    if homogeneous(data):\n",
    "        root.label = data[0][1]\n",
    "        root.classCounts = {root.label: len(data)}\n",
    "        return root\n",
    "\n",
    "    if len(remainingFeatures) == 0:\n",
    "        return majorityVote(data, root)\n",
    "\n",
    "   # find the index of the best feature to split on\n",
    "    bestFeature = max(remainingFeatures, key=lambda index: gain(data, index))\n",
    "\n",
    "    if gain(data, bestFeature) == 0:\n",
    "        return majorityVote(data, root)\n",
    "\n",
    "    root.splitFeature = bestFeature\n",
    "\n",
    "   # add child nodes and process recursively\n",
    "    for dataSubset in splitData(data, bestFeature):\n",
    "        aChild = Node(parent=root)\n",
    "        aChild.splitFeatureValue = dataSubset[0][0][bestFeature]\n",
    "        root.children.append(aChild)\n",
    "\n",
    "        buildDecisionTree(dataSubset, aChild, remainingFeatures - set([bestFeature]))\n",
    "\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree(data):\n",
    "    return buildDecisionTree(data, Node(), set(range(len(data[0][0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, point):\n",
    "\n",
    "    if tree.children == []:\n",
    "        return tree.label\n",
    "    else:\n",
    "        matchingChildren = [child for child in tree.children\n",
    "            if child.splitFeatureValue == point[tree.splitFeature]]\n",
    "\n",
    "    if len(matchingChildren) == 0:\n",
    "         raise Exception(\"Classify is not able to handle noisy data. Use classify2 instead.\")\n",
    "\n",
    "    return classify(matchingChildren[0], point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionarySum(*dicts):\n",
    "    sumDict = {}\n",
    "    for aDict in dicts:\n",
    "          for key in aDict:\n",
    "            if key in sumDict:\n",
    "                sumDict[key] += aDict[key]\n",
    "            else:\n",
    "                sumDict[key] = aDict[key]\n",
    "\n",
    "    return sumDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyNoisy(tree, point):\n",
    "   if tree.children == []:\n",
    "      return tree.classCounts\n",
    "   elif point[tree.splitFeature] == '?':\n",
    "      dicts = [classifyNoisy(child, point) for child in tree.children]\n",
    "      return dictionarySum(*dicts)\n",
    "   else:\n",
    "      matchingChildren = [child for child in tree.children\n",
    "         if child.splitFeatureValue == point[tree.splitFeature]]\n",
    "\n",
    "      return classifyNoisy(matchingChildren[0], point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify2(tree, point):\n",
    "   counts = classifyNoisy(tree, point)\n",
    "\n",
    "   if len(sorted(counts)) == 1:\n",
    "      return sorted(counts)[0]\n",
    "   else:\n",
    "      return max(counts, key=lambda k: counts[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testClassification(data, tree, classifier=classify2):\n",
    "   actualLabels = [label for point, label in data]\n",
    "   predictedLabels = [classifier(tree, point) for point, label in data]\n",
    "\n",
    "   correctLabels = [(1 if a == b else 0) for a,b in zip(actualLabels, predictedLabels)]\n",
    "   return float(sum(correctLabels)) / len(actualLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testTreeSize(noisyData, cleanData):\n",
    "   import random\n",
    "\n",
    "   for i in range(1, len(cleanData)):\n",
    "      tree = decisionTree(random.sample(cleanData, i))\n",
    "      print( str(testClassification(noisyData, tree)) + \", \",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "republican\n",
      "democrat\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "   with open('house-votes-84.csv', 'r') as inputFile:\n",
    "      lines = inputFile.readlines()\n",
    "\n",
    "   data = [line.strip().split(',') for line in lines]\n",
    "   data = [(x[1:], x[0]) for x in data]\n",
    "\n",
    "   cleanData = [x for x in data if '?' not in x[0]]\n",
    "   noisyData = [x for x in data if '?' in x[0]]\n",
    "    \n",
    "   tree = decisionTree(cleanData)\n",
    "   print (classify(tree, ['y' for _ in range(len(data[0][0]))]))\n",
    "   print (classify(tree, ['n' for _ in range(len(data[0][0]))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error with 'clean' data (abstaining votes removed from dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9871244635193133"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testClassification(cleanData,tree,classifier=classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error with 'noisy' data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.963302752293578"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testClassification(data,tree,classifier=classify2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
